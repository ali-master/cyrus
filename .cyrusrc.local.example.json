{
  "$schema": "https://cyrus.usestrict.dev/schema.json",
  "aiProvider": {
    "name": "ollama",
    "model": "llama3.2",
    "baseURL": "http://localhost:11434/v1"
  },
  "features": {
    "securityScan": true,
    "performanceAnalysis": true,
    "codeGeneration": true,
    "refactorSuggestions": true,
    "mentorMode": true
  },
  "languages": ["javascript", "typescript", "python", "java", "go", "rust"],
  "outputFormat": "text",
  "detectLanguage": {
    "enabled": true,
    "confidence": 0.7
  },
  "localModels": {
    "ollama": {
      "models": ["llama3.2", "codellama", "mistral"],
      "defaultModel": "llama3.2"
    }
  }
}
